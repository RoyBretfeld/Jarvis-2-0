# ðŸŽ¤ Voice-Chat-Direct (VCD) - Daily Driver Guide

**Status:** âœ… PRODUCTION READY
**Version:** v1.0 (Phase 9)
**Purpose:** Voice Integration im Terminal fÃ¼r tÃ¤gliche TAIA-Interaktion

---

## ðŸŽ¯ Was ist VCD?

**Voice-Chat-Direct** ist das **Daily Driver Tool** fÃ¼r Voice-Interaktion mit TAIA.

Statt:
- âŒ "Ich schreibe Text, bekomme Text zurÃ¼ck"
- âŒ "Voice ist in API versteckt"
- âŒ "Latenz zwischen Eingabe und Feedback"

Jetzt:
- âœ… "Ich spreche, TAIA antwortet mit Stimme"
- âœ… "Voice ist STANDARD-Interface"
- âœ… "Reflective Thinking hÃ¶rbar"
- âœ… "Text + Voice synchronisiert"

---

## ðŸš€ Quick Start

### Installation
```bash
cd "e:\_____1111____Projekte-Programmierung\Antigravity\The Forge"
npm install
```

### Starten
```bash
# Option 1: npm script
npm run voice

# Option 2: node direktly
node src/voice-chat-direct.js

# Option 3: Alias
npm run vcd
```

### Erstes Mal: Initialization
```
âœ… TAIA Ready (v2.2.0)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ’¬ Start typing or press [SPACEBAR] for voice input
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

> _
```

---

## ðŸ’» Verwendung

### Methode 1: Text Input (Normal Typing)
```
> Hallo TAIA, wie heiÃŸt du?

ðŸ§  [Denkvorgang]: Ich analysiere die Anfrage...
[VOICE] Speaking (powershell): "Ich analysiere..."

ðŸ¤– TAIA: Ich bin TAIA, ein True Artificial Intelligence Agent...
[VOICE] Speaking (powershell): "Ich bin TAIA..."

>
```

### Methode 2: Voice Input (Push-to-Talk)
```
> [DrÃ¼cke LEERTASTE]

ðŸŽ¤ Listening...

[Warte 3-5 Sekunden, spreche ins Mikrofon]

ðŸ“ You: Hallo TAIA, wie geht es dir?

ðŸ§  [Denkvorgang]: Ich prÃ¼fe die Registry...
[VOICE] Speaking (powershell): "Ich prÃ¼fe..."

ðŸ¤– TAIA: Mir geht es gut! Ich bin TAIA und...
[VOICE] Speaking (powershell): "Mir geht es gut..."

>
```

---

## ðŸŽ® Keyboard Controls

| Taste | Aktion |
|-------|--------|
| **LEERTASTE** | Push-to-Talk aktivieren |
| **Text + Enter** | Text-Input senden |
| **Ctrl+C** | Exit + Session speichern |

---

## ðŸ”Š Voice Features in VCD

### 1. Reflective Thinking (mit Voice)
TAIA **denkt laut** bevor Groq antwortet:
```
ðŸ§  [Denkvorgang]: Ich analysiere die Anfrage...
```
- HÃ¶rbar: PowerShell TTS spricht den Gedanken
- WÃ¤hrend: Groq verarbeitet im Hintergrund
- Effekt: FÃ¼hlt sich prÃ¤senter an

### 2. Voice Output (Synchronized)
Response wird **gleichzeitig** gesprochen + angezeigt:
```
ðŸ¤– TAIA: [Antwortext erscheint UND wird gesprochen]
```
- Keine VerzÃ¶gerung
- Text + Voice parallel
- Native Windows TTS (PowerShell SAPI)

### 3. Session Logging
Jede Interaktion wird geloggt:
```
brain/voice-sessions/vcd-1707585600000.json
```

Inhalt:
```json
[
  {
    "type": "voice_input",
    "timestamp": "2026-02-11T...",
    "text": "Hallo TAIA"
  },
  {
    "type": "response",
    "timestamp": "2026-02-11T...",
    "input": "Hallo TAIA",
    "output": "Hallo! Ich bin TAIA..."
  }
]
```

---

## ðŸ”§ Konfiguration

### Voice Settings Ã¤ndern
In `src/voice-chat-direct.js` (Constructor):

```javascript
this.taia = new AgentCore({
  voiceOutput: true,        // âœ… Voice An/Aus
  reflectAloud: true,       // âœ… Denken laut sprechen
  reflectiveDelay: 200,     // ms vor Groq call
  debug: false              // Logging detail
});
```

### Language Settings
```javascript
// In AgentCore v2.2:
this.voice = new VoiceEngine({
  language: 'de',    // German
  rate: -1,          // Slower = clearer
  volume: 85         // Optimal volume
});

this.ears = new EarsEngine({
  language: 'de',
  recordDuration: 5  // Seconds
});
```

---

## ðŸŽ¯ Workflow Beispiele

### Example 1: Daily Status Check
```bash
npm run voice
```
```
> Guten Morgen, Status?

ðŸ§  [Denkvorgang]: Ich prÃ¼fe die Registry...
ðŸ¤– TAIA: Guten Morgen! Der Status ist optimal...

> [LEERTASTE] Systemauslastung?

ðŸ“ You: Systemauslastung?
ðŸ¤– TAIA: Die CPU-Auslastung betrÃ¤gt...
```

### Example 2: Hands-Free Operation
```
[Im Office, HÃ¤nde voll]
> [LEERTASTE]
ðŸŽ¤ Listening...
[Sprich]: "Was ist die aktuelle Uhrzeit?"
ðŸ¤– TAIA: [Spricht]: "Es ist 14:32 Uhr."
```

### Example 3: Mixed Input (Text + Voice)
```
> ErklÃ¤re mir die Registry

ðŸ¤– TAIA: [ErklÃ¤rt mit Voice+Text]

> [LEERTASTE]
ðŸ“ You: Und wie funktioniert die Veritas-Ebene?

ðŸ¤– TAIA: [Antwortet nur per Voice+Text]
```

---

## ðŸ” Troubleshooting

### Problem: Mikrofon wird nicht erkannt

**LÃ¶sung:**
```bash
# ÃœberprÃ¼fe SystemlautstÃ¤rke
# Windows: Sound Settings â†’ Input device
# Check volume mixer
```

### Problem: Voice zu laut / zu leise

**LÃ¶sung in agent-core.js:**
```javascript
this.voice = new VoiceEngine({
  volume: 50,  // Leiser (0-100)
  // oder
  volume: 100  // Lauter
});
```

### Problem: Spreche, aber TAIA antwortet nicht

**LÃ¶sung:**
1. ÃœberprÃ¼fe GROQ_API_KEY in `.env`
2. Test mit Text-Input: `> Hallo`
3. ÃœberprÃ¼fe Internet-Connection

### Problem: Text wird angezeigt, aber nicht gesprochen

**LÃ¶sung:**
```javascript
// In VCD Constructor:
voiceOutput: true,  // Muss true sein
reflectAloud: true  // FÃ¼r Denken-laut-sprechen
```

---

## ðŸ“Š Performance

| Aktion | Latenz |
|--------|--------|
| Text-Input â†’ Response | 1-2s |
| Voice-Input Aufnahme | 3-5s |
| Groq Processing | ~1s |
| Voice Output (TTS) | <1s |
| **Gesamt (Voice Loop)** | **5-7s** |

---

## ðŸŽ™ï¸ Audio Quality

### Input (STT)
- **API:** Groq Whisper
- **Sample Rate:** 16000 Hz (CD-QualitÃ¤t)
- **Format:** LPCM WAV
- **Language:** Deutsch (konfigurierbar)

### Output (TTS)
- **Engine:** Windows PowerShell SAPI (native)
- **Language:** Deutsch
- **Rate:** -1 (slow for clarity)
- **Volume:** 85% (optimized)

---

## ðŸ’¾ Session Management

### Session speichert:
- Alle Text-Inputs
- Alle Voice-Inputs
- Alle Responses
- Timestamps
- Error Messages

### Session-Dateien:
```
brain/voice-sessions/
â”œâ”€â”€ vcd-1707585600000.json    # Session 1
â”œâ”€â”€ vcd-1707586000000.json    # Session 2
â””â”€â”€ ...
```

### Session auswerten:
```bash
# Letzte Session anschauen
cat brain/voice-sessions/$(ls -t brain/voice-sessions | head -1)
```

---

## ðŸ” Security & Privacy

### Audio-Dateien:
- Nur wÃ¤hrend Recording im RAM
- Wird zu Groq Whisper geschickt (encrypted HTTPS)
- Wird nicht lokal gespeichert (nur Transkription)

### Logs:
- Sessions speichern **nur Text**, nicht Audio
- Dateien im `brain/voice-sessions/` Verzeichnis
- Git ignoriert diese Dateien automatisch

### API Keys:
- GROQ_API_KEY aus `.env` geladen
- Nicht in Logs oder Output
- Nicht in Sessions gespeichert

---

## ðŸš€ Advanced Usage

### Bash Integration
```bash
#!/bin/bash
# voice-daily.sh - TÃ¤glicher Voice-Check
npm run voice << EOF
Status?
Speicher?
Backup-Status?
exit
EOF
```

### Docker (geplant fÃ¼r Phase 9.5)
```bash
docker run -it --device /dev/snd taia-voice npm run voice
```

### CI/CD Pipeline (geplant)
```yaml
- name: Voice System Test
  run: npm run voice -- --test
```

---

## ðŸ“ Changelog

### v1.0 (2026-02-11)
- âœ… Push-to-Talk im Terminal
- âœ… Synchronized Voice Output
- âœ… Session Logging
- âœ… Reflective Thinking mit Voice
- âœ… Text + Voice Input/Output

### v1.1 (Geplant)
- [ ] Multi-language support
- [ ] Voice profiles (different voices)
- [ ] Audio file input
- [ ] Session playback

### v2.0 (Geplant)
- [ ] WebSocket streaming
- [ ] Real-time transcription
- [ ] Voice emotion detection
- [ ] Advanced session analytics

---

## ðŸŽ¯ Next Steps

Nach VCD:

1. **Phase 9.2:** Voice Personality (different voices)
2. **Phase 9.3:** Wake-word detection ("TAIA...")
3. **Phase 9.4:** Production Deployment (Docker)
4. **Phase 9.5:** Advanced Analytics

---

## ðŸ“ž Support

### HÃ¤ufige Fragen:

**Q: Kann ich mehrere Sessions parallel haben?**
A: Nein, VCD ist single-session. Aber Sessions kÃ¶nnen geÃ¶ffnet und analysiert werden.

**Q: Kann ich Voice Output abschalten?**
A: Ja:
```javascript
voiceOutput: false,  // Nur Text
```

**Q: Funktioniert das auf Linux/macOS?**
A: Ja, aber TTS verwendet Piper statt PowerShell SAPI. Text-Input funktioniert Ã¼berall.

**Q: Kann ich Audio-Dateien als Input nutzen?**
A: Ja, Ã¼ber `/api/voice/transcribe` endpoint (Phase 8.5). In VCD noch nicht, geplant fÃ¼r v1.1.

---

## ðŸŽ‰ Summary

**Voice-Chat-Direct macht TAIA zur Stimme in deinem Terminal.**

Von hier aus:
- âœ… Spreche normal, TAIA hÃ¶rt zu
- âœ… TAIA denkt laut, wÃ¤hrend sie verarbeitet
- âœ… TAIA antwortet mit Stimme + Text
- âœ… Sessions werden protokolliert
- âœ… Alles funktioniert offline (auÃŸer Groq)

**Das ist die Zukunft der Agent-Interaction.**

---

**Dokumentation:** 2026-02-11
**Build:** TAIA v2.2.0 + VCD v1.0
**Status:** ðŸŸ¢ PRODUCTION READY
