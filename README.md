# The Forge ğŸ”¨ - TAIA Agent Architecture

**TAIA** = True Artificial Intelligence Agent

A modular AI agent framework with full sensory integration, autonomous decision-making, and reflexive command handling.

---

## ğŸ“Š Project Status

### âœ… Completed Phases

| Phase | Component | Status | Tests |
|-------|-----------|--------|-------|
| 0 | Security & Config | âœ… | 9 |
| 1 | Utils & Infrastructure | âœ… | 69 |
| 2 | Repository Pattern | âœ… | 69 |
| 3 | Service Layer | âœ… | 79 |
| 4 | API Refactoring | âœ… | - |

**Total:** 226 tests passing âœ…

### ğŸš€ Current Phase: TAIA Senses Integration

**Focus:** Audio Input (Speech-to-Text) + Voice Output

#### What We're Building:
- `src/senses/ears.py` - Local speech recognition (Faster-Whisper)
- `src/senses/voice.py` - Text-to-speech feedback
- Hard-wired reflexive commands (Status, Sentinel-Check, Sleep/Wake)
- Streamlit GUI with audio feedback

#### Status:
- â³ Ears (Speech-to-Text) - IN PROGRESS
- â³ Voice (Text-to-Speech) - PLANNED
- â³ Streamlit integration - PLANNED

---

## ğŸ—ï¸ Architecture

```
TAIA Agent
â”œâ”€â”€ ğŸ¯ Core (src/core/)
â”‚   â”œâ”€â”€ agent.py - Main intelligence
â”‚   â”œâ”€â”€ llm.py - Language model interface
â”‚   â”œâ”€â”€ config/ - Configuration system
â”‚   â””â”€â”€ container.py - Dependency injection
â”‚
â”œâ”€â”€ ğŸ‘ï¸ Senses (src/senses/)
â”‚   â”œâ”€â”€ ears.py - Speech input [WIP]
â”‚   â”œâ”€â”€ voice.py - Speech output [PLANNED]
â”‚   â”œâ”€â”€ vision.py - Image processing
â”‚   â”œâ”€â”€ k8s.py - System monitoring
â”‚   â””â”€â”€ collector.py - Data collection
â”‚
â”œâ”€â”€ ğŸ§  Repositories (src/repositories/)
â”‚   â”œâ”€â”€ base.py - Abstract interface
â”‚   â”œâ”€â”€ memory.py - MEMORY.md operations
â”‚   â”œâ”€â”€ soul.py - Agent personality
â”‚   â””â”€â”€ error_db.py - Error tracking
â”‚
â””â”€â”€ ğŸ“¡ API (src/api/)
    â”œâ”€â”€ routes/ - Modular endpoints
    â”‚   â”œâ”€â”€ chat.js
    â”‚   â”œâ”€â”€ config.js
    â”‚   â”œâ”€â”€ memory.js
    â”‚   â””â”€â”€ vision.js
    â””â”€â”€ server-refactored.js - Express server
```

---

## ğŸš€ Quick Start

### Prerequisites
```bash
python 3.10+
node 18+
```

### Installation
```bash
# Install Python dependencies
pip install -r requirements.txt

# Install Node dependencies
npm install
```

### Run Agent
```bash
streamlit run src/core/agent.py
```

### Run Tests
```bash
pytest
```

---

## ğŸ¤ Current Sprint: Ears Implementation

### Tasks
1. [ ] Update requirements.txt with audio libraries
2. [ ] Implement src/senses/ears.py (ForgeEars class)
3. [ ] Implement src/senses/voice.py (ForgeVoice class)
4. [ ] Integrate with src/core/agent.py
5. [ ] Add Streamlit GUI feedback

### Dependencies (To Install)
- `faster-whisper>=0.10.0` - Local speech-to-text
- `openWakeWord>=0.1.0` - Wake-word detection ("TAIA")
- `pyttsx3>=2.90` - Text-to-speech
- `pyaudio` - Microphone input

---

## ğŸ“ Documentation

- **[SESSION_LOG.md](SESSION_LOG.md)** - Active work log (live updates)
- **[src/senses/README.md](src/senses/README.md)** - Senses subsystem
- **[MEMORY.md](../../../.claude/projects/e-------1111----Projekte-Programmierung-Antigravity-The-Forge/memory/MEMORY.md)** - Global project memory

---

## ğŸ”— Key Files

| File | Purpose |
|------|---------|
| `src/core/agent.py` | Main TAIA agent |
| `src/senses/ears.py` | Speech recognition [WIP] |
| `src/senses/voice.py` | Speech output [PLANNED] |
| `src/api/server-refactored.js` | API server |
| `requirements.txt` | Python dependencies |
| `SESSION_LOG.md` | Active work checkpoint |

---

## ğŸ¯ Next Milestone

**Goal:** TAIA responds to voice commands with local speech-to-text

**Timeline:**
- Day 1-2: Audio libraries + ears.py
- Day 2-3: Voice.py + integration
- Day 3-4: Streamlit GUI + testing

---

## ğŸ›¡ï¸ Security Notes

- âœ… All audio processing is local (no cloud APIs)
- âœ… No API keys stored in git
- âœ… Credentials managed via .env

---

**Last Updated:** 2026-02-08
**Contributor:** Claude (Haiku 4.5)
