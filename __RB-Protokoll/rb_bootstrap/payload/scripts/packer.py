#!/usr/bin/env python3
"""
RB-Framework Packer (v2.1)
Generates context dumps for agents/debugging
- Cross-platform (pathlib)
- Smart directory detection
- Configurable via environment
"""
import os
import re
import time
from pathlib import Path
from typing import Set

# Default includes - automatically detect common project structures
DEFAULT_INCLUDE_DIRS = ["docs/_rb", "src", "tests", "scripts"]
COMMON_PROJECT_DIRS = [
    "backend", "frontend", "server", "client", 
    "app", "lib", "pkg", "packages",
    "api", "web", "core"
]

EXCLUDE_DIRS = {".git", "docs/_archive", "node_modules", ".venv", "__pycache__", 
                "dist", "build", ".next", ".nuxt", "vendor", 
                ".pytest_cache", "coverage", ".idea", ".vscode"}

MAX_BYTES = 2_000_000

BLOCK_FILES = [r"\.env$", r"\.pem$", r"\.key$", r"\.db$", r"\.sqlite$", r"\.pyc$"]

def cleanup_old_dumps(dump_dir: Path, current_dump: Path):
    """Keep only the latest dump file in the directory."""
    print("üßπ Cleaning up old dumps...")
    for item in dump_dir.glob("PROJECT_CONTEXT_DUMP_*.txt"):
        if item.is_file() and item != current_dump:
            try:
                item.unlink()
                print(f"   üóëÔ∏è  Deleted: {item.name}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Could not delete {item.name}: {e}")

def is_blocked(path: Path) -> bool:
    """Check if file should be excluded from dump."""
    path_str = str(path).replace("\\", "/")
    return any(re.search(pattern, path_str, re.IGNORECASE) for pattern in BLOCK_FILES)

def detect_project_dirs(repo_root: Path) -> Set[Path]:
    """Auto-detect project directories based on common patterns."""
    detected = set()
    
    # Always include these if they exist
    for dir_name in DEFAULT_INCLUDE_DIRS:
        dir_path = repo_root / dir_name
        if dir_path.is_dir():
            detected.add(dir_path)
    
    # Scan for common project structures
    for item in repo_root.iterdir():
        if not item.is_dir():
            continue
        if item.name in EXCLUDE_DIRS or item.name.startswith("."):
            continue
        if item.name in COMMON_PROJECT_DIRS:
            detected.add(item)
    
    return detected

def should_exclude_dir(dir_path: Path) -> bool:
    """Check if directory should be excluded."""
    return any(excluded in dir_path.parts for excluded in EXCLUDE_DIRS)

def walk_and_collect(base_dir: Path, max_size: int) -> list:
    """Walk directory and collect file paths."""
    collected = []
    
    for item in base_dir.rglob("*"):
        if item.is_dir():
            continue
        
        # Skip excluded directories
        if should_exclude_dir(item):
            continue
        
        # Skip blocked files
        if is_blocked(item):
            continue
        
        # Skip large files
        try:
            if item.stat().st_size > max_size:
                continue
        except OSError:
            continue
        
        collected.append(item)
    
    return sorted(collected)

def main():
    print("üì¶ RB-Framework Packer v2.1")
    print("=" * 50)
    
    repo_root = Path.cwd()
    timestamp = time.strftime("%Y-%m-%d_%H-%M")
    
    # Secure output directory
    dump_dir = repo_root / ".rb_dumps"
    dump_dir.mkdir(exist_ok=True)
    
    output_file = dump_dir / f"PROJECT_CONTEXT_DUMP_{timestamp}.txt"
    
    # Get custom include dirs from environment
    custom_includes = os.environ.get("RB_PACK_INCLUDE", "")
    if custom_includes:
        include_dirs = {repo_root / d.strip() for d in custom_includes.split(",") if d.strip()}
        print(f"üìÇ Using custom includes: {', '.join(d.name for d in include_dirs)}")
    else:
        # Auto-detect
        include_dirs = detect_project_dirs(repo_root)
        print(f"üîç Auto-detected directories: {', '.join(d.name for d in include_dirs)}")
    
    if not include_dirs:
        print("‚ö†Ô∏è  No directories found to pack! Aborting.")
        return
    
    # Collect all files
    all_files = []
    for dir_path in include_dirs:
        if not dir_path.exists():
            print(f"‚ö†Ô∏è  Skipping non-existent: {dir_path.name}")
            continue
        all_files.extend(walk_and_collect(dir_path, MAX_BYTES))
    
    print(f"üìÑ Found {len(all_files)} file(s) to pack")
    
    # Write dump
    with output_file.open("w", encoding="utf-8") as w:
        w.write(f"# Project Context Dump: {timestamp}\n")
        w.write(f"# Generated by RB-Framework Packer v2.0\n")
        w.write(f"# Repository: {repo_root.name}\n")
        w.write(f"# Total files: {len(all_files)}\n")
        w.write("\n" + "=" * 80 + "\n\n")
        
        for file_path in all_files:
            rel_path = file_path.relative_to(repo_root)
            w.write(f"\n\n{'=' * 80}\n")
            w.write(f"FILE: {rel_path}\n")
            w.write(f"{'=' * 80}\n\n")
            
            try:
                content = file_path.read_text(encoding="utf-8", errors="ignore")
                w.write(content)
            except Exception as e:
                w.write(f"<ERROR: Could not read file: {e}>")
    
    file_size_kb = output_file.stat().st_size / 1024
    print(f"‚úÖ Context dump created: {output_file.name}")
    print(f"üìä Size: {file_size_kb:.1f} KB")
    
    # Keep only the latest file
    cleanup_old_dumps(dump_dir, output_file)
    
    print(f"\nüí° Tip: Use 'RB_PACK_INCLUDE=dir1,dir2' to customize includes")

if __name__ == "__main__":
    main()

